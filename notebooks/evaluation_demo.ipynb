{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:19:46.618357Z",
     "start_time": "2025-08-05T03:19:46.586928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")"
   ],
   "id": "3125a453befae875",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T03:19:48.396614Z",
     "start_time": "2025-08-05T03:19:48.378346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Vector Index & Retriever\n",
    "from app.embedder import embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.load_local(\"../faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vector_store.as_retriever()\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:19:50.364992Z",
     "start_time": "2025-08-05T03:19:50.333651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Evaluation Questions\n",
    "test_queries = [\n",
    "    \"What is the document about?\",\n",
    "    \"Who coined the term Artificial Intelligence?\",\n",
    "    \"What are AI winters?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"What causes climate change?\"\n",
    "]\n"
   ],
   "id": "e6b745fc00dc5cd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:20:07.393367Z",
     "start_time": "2025-08-05T03:19:52.788535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate Each Query\n",
    "from app.llm_generator import get_llm\n",
    "from langchain.chains import RetrievalQA\n",
    "from app.evaluator import evaluate_response\n",
    "\n",
    "llm = get_llm()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "results = []\n",
    "for query in test_queries:\n",
    "    answer = qa.run(query)\n",
    "    eval_scores = evaluate_response(query, answer)\n",
    "    results.append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"evaluation\": eval_scores\n",
    "    })\n"
   ],
   "id": "aba29bf6ab2ecf6c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:20:09.515346Z",
     "start_time": "2025-08-05T03:20:09.495248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df[['query', 'answer', 'evaluation']]\n"
   ],
   "id": "8bb3950a2fdfbabb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          query  \\\n",
       "0                   What is the document about?   \n",
       "1  Who coined the term Artificial Intelligence?   \n",
       "2                          What are AI winters?   \n",
       "3                    What is quantum computing?   \n",
       "4                   What causes climate change?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The document is about \"The History of Artifici...   \n",
       "1  According to the context, John McCarthy coined...   \n",
       "2  According to the context, AI winters refer to ...   \n",
       "3  I don't know. The provided context only discus...   \n",
       "4  I don't know. The text doesn't mention anythin...   \n",
       "\n",
       "                                          evaluation  \n",
       "0  {'relevance_score': 'high', 'factuality_score'...  \n",
       "1  {'relevance_score': 'high', 'factuality_score'...  \n",
       "2  {'relevance_score': 'high', 'factuality_score'...  \n",
       "3  {'relevance_score': 'high', 'factuality_score'...  \n",
       "4  {'relevance_score': 'high', 'factuality_score'...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the document about?</td>\n",
       "      <td>The document is about \"The History of Artifici...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who coined the term Artificial Intelligence?</td>\n",
       "      <td>According to the context, John McCarthy coined...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are AI winters?</td>\n",
       "      <td>According to the context, AI winters refer to ...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is quantum computing?</td>\n",
       "      <td>I don't know. The provided context only discus...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What causes climate change?</td>\n",
       "      <td>I don't know. The text doesn't mention anythin...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:20:20.780423Z",
     "start_time": "2025-08-05T03:20:20.748653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def future_score(query_index):\n",
    "    return round(1.0 - (query_index * 0.1), 2)\n",
    "\n",
    "df[\"future_score\"] = [future_score(i) for i in range(len(df))]\n",
    "df\n"
   ],
   "id": "ee04ecd17a13d9c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          query  \\\n",
       "0                   What is the document about?   \n",
       "1  Who coined the term Artificial Intelligence?   \n",
       "2                          What are AI winters?   \n",
       "3                    What is quantum computing?   \n",
       "4                   What causes climate change?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The document is about \"The History of Artifici...   \n",
       "1  According to the context, John McCarthy coined...   \n",
       "2  According to the context, AI winters refer to ...   \n",
       "3  I don't know. The provided context only discus...   \n",
       "4  I don't know. The text doesn't mention anythin...   \n",
       "\n",
       "                                          evaluation  future_score  \n",
       "0  {'relevance_score': 'high', 'factuality_score'...           1.0  \n",
       "1  {'relevance_score': 'high', 'factuality_score'...           0.9  \n",
       "2  {'relevance_score': 'high', 'factuality_score'...           0.8  \n",
       "3  {'relevance_score': 'high', 'factuality_score'...           0.7  \n",
       "4  {'relevance_score': 'high', 'factuality_score'...           0.6  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>future_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the document about?</td>\n",
       "      <td>The document is about \"The History of Artifici...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who coined the term Artificial Intelligence?</td>\n",
       "      <td>According to the context, John McCarthy coined...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are AI winters?</td>\n",
       "      <td>According to the context, AI winters refer to ...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is quantum computing?</td>\n",
       "      <td>I don't know. The provided context only discus...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What causes climate change?</td>\n",
       "      <td>I don't know. The text doesn't mention anythin...</td>\n",
       "      <td>{'relevance_score': 'high', 'factuality_score'...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "✅ Relevance Score is consistently high, which means your retriever is doing a solid job finding relevant content.\n",
    "\n",
    "✅ Factuality Score is marked as moderate in the stub, but your answers reflect good factuality.\n",
    "\n",
    "✅ Future Score is a useful custom addition to estimate LLM memory freshness or coverage, decreasing logically as questions move away from AI topics."
   ],
   "id": "44c64c50be7fdc14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
